{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isXKjO6eVl1i"
      },
      "outputs": [],
      "source": [
        "Create a board of Connect4 first"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "NUM_COLUMNS = 7\n",
        "COLUMN_HEIGHT = 6\n",
        "FOUR = 4"
      ],
      "metadata": {
        "id": "KRMSY32KYFZv"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def valid_moves(board):\n",
        "    \"\"\"Returns columns where a disc may be played\"\"\"\n",
        "    return [n for n in range(NUM_COLUMNS) if board[n, COLUMN_HEIGHT - 1] == 0]\n",
        "\n",
        "\n",
        "def play(board, column, player):\n",
        "    \"\"\"Updates `board` as `player` drops a disc in `column`\"\"\"\n",
        "    (index,) = next((i for i, v in np.ndenumerate(board[column]) if v == 0))\n",
        "    board[column, index] = player\n",
        "\n",
        "\n",
        "def take_back(board, column):\n",
        "    \"\"\"Updates `board` removing top disc from `column`\"\"\"\n",
        "    (index,) = [i for i, v in np.ndenumerate(board[column]) if v != 0][-1]\n",
        "    board[column, index] = 0\n",
        "\n",
        "\n",
        "def four_in_a_row(board, player):\n",
        "    \"\"\"Checks if `player` has a 4-piece line\"\"\"\n",
        "    return (\n",
        "        any(\n",
        "            all(board[c, r] == player)\n",
        "            for c in range(NUM_COLUMNS)\n",
        "            for r in (list(range(n, n + FOUR)) for n in range(COLUMN_HEIGHT - FOUR + 1))\n",
        "        )\n",
        "        or any(\n",
        "            all(board[c, r] == player)\n",
        "            for r in range(COLUMN_HEIGHT)\n",
        "            for c in (list(range(n, n + FOUR)) for n in range(NUM_COLUMNS - FOUR + 1))\n",
        "        )\n",
        "        or any(\n",
        "            np.all(board[diag] == player)\n",
        "            for diag in (\n",
        "                (range(ro, ro + FOUR), range(co, co + FOUR))\n",
        "                for ro in range(0, NUM_COLUMNS - FOUR + 1)\n",
        "                for co in range(0, COLUMN_HEIGHT - FOUR + 1)\n",
        "            )\n",
        "        )\n",
        "        or any(\n",
        "            np.all(board[diag] == player)\n",
        "            for diag in (\n",
        "                (range(ro, ro + FOUR), range(co + FOUR - 1, co - 1, -1))\n",
        "                for ro in range(0, NUM_COLUMNS - FOUR + 1)\n",
        "                for co in range(0, COLUMN_HEIGHT - FOUR + 1)\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "\n",
        "def _mc(board, player):\n",
        "    p = -player\n",
        "    while valid_moves(board):\n",
        "        p = -p\n",
        "        c = np.random.choice(valid_moves(board))\n",
        "        play(board, c, p)\n",
        "        if four_in_a_row(board, p):\n",
        "            return p\n",
        "    return 0\n",
        "\n",
        "\n",
        "def montecarlo(board, player):\n",
        "    montecarlo_samples = 100\n",
        "    cnt = Counter(_mc(np.copy(board), player) for _ in range(montecarlo_samples))\n",
        "    return (cnt[1] - cnt[-1]) / montecarlo_samples\n",
        "\n",
        "\n",
        "def eval_board(board, player):\n",
        "    if four_in_a_row(board, 1):\n",
        "        # Alice won\n",
        "        return 1\n",
        "    elif four_in_a_row(board, -1):\n",
        "        # Bob won\n",
        "        return -1\n",
        "    else:\n",
        "        # Not terminal, let's simulate...\n",
        "        return montecarlo(board, player)"
      ],
      "metadata": {
        "id": "15jBWaXpmFcw"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PLAYERS = {1: \"A\", -1: \"B\"}\n",
        "MAX_ROUNDS = NUM_COLUMNS * COLUMN_HEIGHT\n",
        "NUM_ITERATIONS = 10\n",
        "def initialize_board():\n",
        "    return np.zeros((NUM_COLUMNS, COLUMN_HEIGHT), dtype=np.byte)\n",
        "    \n",
        "def display(board):\n",
        "    for j in reversed(range(COLUMN_HEIGHT)):\n",
        "        for i in range(NUM_COLUMNS):\n",
        "            cell = board[i][j]\n",
        "            if cell == 1:\n",
        "                print(PLAYERS[1], end=\" \")\n",
        "            elif cell == -1:\n",
        "                print(PLAYERS[-1], end=\" \")\n",
        "            else:\n",
        "                print(\"-\", end=\" \")\n",
        "        print()\n",
        "\n",
        "\n",
        "def round_number(board):\n",
        "    return np.count_nonzero(board)\n",
        "\n",
        "def terminal_state(board):\n",
        "    if round_number(board) == MAX_ROUNDS:    # draw\n",
        "        return 0\n",
        "    if four_in_a_row(board, 1):\n",
        "        return 1\n",
        "    elif four_in_a_row(board, -1):\n",
        "        return -1\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "dQfVfp4jmVb9"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set monte-carlo tree as the default opponent\n",
        "from __future__ import annotations\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, board: np.ndarray, player: int, parent: Node = None, move: int = None):\n",
        "        self.board = np.copy(board)\n",
        "        self.player = player    # player who did the previous move\n",
        "        self.parent = parent\n",
        "        self.move = move        # previous move that brought in this state\n",
        "        self.num_visits = 0\n",
        "        self.num_wins = 0\n",
        "        self.children = []\n",
        "        self.next_moves = valid_moves(board)\n",
        "\n",
        "    def selection(self):\n",
        "        def UCB1(node):\n",
        "            c = np.sqrt(2)\n",
        "            exploitation = node.num_wins / node.num_visits\n",
        "            exploration = c * np.sqrt(np.log(node.parent.num_visits) / node.num_visits)\n",
        "            return exploitation + exploration\n",
        "        \n",
        "        return max(self.children, key=UCB1)\n",
        "\n",
        "    def expand(self, move):\n",
        "        player = -self.player     \n",
        "        new_board = np.copy(self.board)\n",
        "        play(new_board, move, player)\n",
        "        self.next_moves.remove(move)\n",
        "        child = Node(new_board, player, self, move)\n",
        "        self.children.append(child)\n",
        "        return child\n",
        "    def simulate(self):\n",
        "        p = -self.player\n",
        "        board = np.copy(self.board)\n",
        "        while valid_moves(board):\n",
        "            move = np.random.choice(valid_moves(board))\n",
        "            play(board, move, p)\n",
        "            if four_in_a_row(board, p):\n",
        "                return p\n",
        "            p = -p\n",
        "        \n",
        "        return 0 # DRAW\n",
        "\n",
        "    def backpropagate(self, winner):\n",
        "        node = self\n",
        "        while node is not None:\n",
        "            if winner == 0:   # draw\n",
        "                node.num_wins += 0.5\n",
        "            elif winner == node.player:\n",
        "                node.num_wins += 1      \n",
        "            node.num_visits += 1\n",
        "            node = node.parent"
      ],
      "metadata": {
        "id": "TlRx3cy0mYG5"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MCTS(board: np.ndarray, player: int, num_iterations: int = NUM_ITERATIONS):\n",
        "    # the player in the node is the one who did the previous move\n",
        "    root = Node(board, -player, parent=None, move=None)\n",
        "\n",
        "    for _ in range(num_iterations):\n",
        "        node = root\n",
        "\n",
        "        # SELECTION (tree traversal)\n",
        "        while len(node.children) != 0 and len(node.next_moves) == 0:  # until terminal or not fully expanded node\n",
        "            node = node.selection()\n",
        "\n",
        "        # EXPANSION        \n",
        "        if len(node.next_moves) > 0:\n",
        "            move = np.random.choice(node.next_moves)\n",
        "            node = node.expand(move)\n",
        "\n",
        "        # SIMULATION (ROLLOUT)\n",
        "        winner = terminal_state(node.board)\n",
        "        if winner is None:\n",
        "            winner = node.simulate()\n",
        "\n",
        "        # BACKPROPAGATION\n",
        "        node.backpropagate(winner)\n",
        "            \n",
        "    # Return most promising move from root (highest score)\n",
        "    best_node = max(root.children, key=lambda x: x.num_wins/x.num_visits)\n",
        "    return best_node.move"
      ],
      "metadata": {
        "id": "nzuksqITmjRW"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PLAYERS = {1: \"A\", -1: \"B\"}\n",
        "MAX_ROUNDS = NUM_COLUMNS * COLUMN_HEIGHT\n",
        "MAX_DEPTH = 3\n",
        "MC_ITERATIONS = 20\n",
        "SEARCH_ORDER = [3, 2, 4, 1, 5, 0, 6]\n",
        "def initialize_board():\n",
        "    return np.zeros((NUM_COLUMNS, COLUMN_HEIGHT), dtype=np.byte)\n",
        "    \n",
        "def display(board):\n",
        "    for j in reversed(range(COLUMN_HEIGHT)):\n",
        "        for i in range(NUM_COLUMNS):\n",
        "            cell = board[i][j]\n",
        "            if cell == 1:\n",
        "                print(PLAYERS[1], end=\" \")\n",
        "            elif cell == -1:\n",
        "                print(PLAYERS[-1], end=\" \")\n",
        "            else:\n",
        "                print(\"-\", end=\" \")\n",
        "        print()\n",
        "\n",
        "\n",
        "def round_number(board):\n",
        "    return np.count_nonzero(board)\n",
        "#minimax\n",
        "def can_win_next_move(board, player, moves=None, round_num=None):\n",
        "    if moves is None:\n",
        "        moves = valid_moves(board)\n",
        "    \n",
        "    if round_num is None:\n",
        "        round_num = round_number(board)\n",
        "\n",
        "    for m in moves:\n",
        "        play(board, m, player)\n",
        "        score = None\n",
        "        if four_in_a_row(board, player):\n",
        "            score = (MAX_ROUNDS - (round_num - 1)) // 2\n",
        "        take_back(board, m)\n",
        "        if score:\n",
        "            return score, m\n",
        "\n",
        "    return None, None\n",
        "def mc_simulation(board: np.ndarray, player: int):\n",
        "    best_score = -MAX_ROUNDS\n",
        "    best_move = None\n",
        "    \n",
        "    for _ in range(MC_ITERATIONS):\n",
        "        move = np.random.choice(valid_moves(board))\n",
        "        \n",
        "        tmp_board = np.copy(board)\n",
        "        tmp_player = player\n",
        "        tmp_move = move\n",
        "        while True:\n",
        "            play(tmp_board, tmp_move, tmp_player)\n",
        "\n",
        "            # Terminal conditions\n",
        "            if round_number(tmp_board) == MAX_ROUNDS:\n",
        "                score = 0\n",
        "                break\n",
        "            if four_in_a_row(tmp_board, tmp_player):\n",
        "                if tmp_player == player:\n",
        "                    score = (MAX_ROUNDS - (round_number(tmp_board) - 1)) // 2\n",
        "                else:\n",
        "                    score = -((MAX_ROUNDS - (round_number(tmp_board) - 1)) // 2)\n",
        "                break\n",
        "\n",
        "            tmp_move = np.random.choice(valid_moves(tmp_board))\n",
        "            tmp_player = -tmp_player\n",
        "\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_move = move\n",
        "        \n",
        "    return best_score, best_move\n",
        "def minimax(board: np.ndarray, player: int, depth: int, alpha: int, beta: int, max_depth: int = MAX_DEPTH):\n",
        "    round_num = round_number(board)\n",
        "\n",
        "    if round_num == MAX_ROUNDS:\n",
        "        return 0, None\n",
        "\n",
        "    moves = valid_moves(board)\n",
        "    score, m = can_win_next_move(board, player, moves, round_num)\n",
        "\n",
        "    if score:\n",
        "        return score, m\n",
        "\n",
        "    max_score = (MAX_ROUNDS - (round_num + 1)) // 2\n",
        "    beta = min(beta, max_score)\n",
        "\n",
        "    if alpha >= beta:\n",
        "        return beta, None\n",
        "\n",
        "    if depth > max_depth:\n",
        "        return mc_simulation(board, player)\n",
        "\n",
        "    best_move = None\n",
        "    for m in SEARCH_ORDER:\n",
        "        if m in moves:\n",
        "            play(board, m, player)\n",
        "            score, _ = minimax(board, -player, depth + 1, -beta, -alpha)\n",
        "            score = -score\n",
        "            take_back(board, m)\n",
        "\n",
        "            if score >= beta:\n",
        "                return score, m\n",
        "\n",
        "            if score > alpha:\n",
        "                alpha = score\n",
        "                best_move = m\n",
        "\n",
        "    return alpha, best_move\n"
      ],
      "metadata": {
        "id": "TxVqB1t1mvqa"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, alpha=0.5, gamma=0.9, epsilon=0.1):\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.q_table = {}\n",
        "\n",
        "    def state_key(self, board):\n",
        "        return board.tobytes()\n",
        "\n",
        "    def select_action(self, board, valid_actions):\n",
        "        state_key = self.state_key(board)\n",
        "        if state_key not in self.q_table:\n",
        "            self.q_table[state_key] = np.zeros(NUM_COLUMNS)\n",
        "\n",
        "        if random.random() < self.epsilon:\n",
        "            return random.choice(valid_actions)\n",
        "        else:\n",
        "            q_values = self.q_table[state_key]\n",
        "            best_actions = [action for action, value in enumerate(q_values) if action in valid_actions and value == max(q_values[valid_actions])]\n",
        "            return random.choice(best_actions)\n",
        "\n",
        "    def update(self, old_board, action, reward, new_board):\n",
        "        old_state_key = self.state_key(old_board)\n",
        "        new_state_key = self.state_key(new_board)\n",
        "\n",
        "        if new_state_key not in self.q_table:\n",
        "            self.q_table[new_state_key] = np.zeros(NUM_COLUMNS)\n",
        "\n",
        "        old_q_value = self.q_table[old_state_key][action]\n",
        "        max_new_q_value = np.max(self.q_table[new_state_key])\n",
        "\n",
        "        self.q_table[old_state_key][action] += self.alpha * (reward + self.gamma * max_new_q_value - old_q_value)\n",
        "\n",
        "\n",
        "def play_game(agent):\n",
        "    board = initialize_board()\n",
        "    player = 1\n",
        "    while terminal_state(board) is None:\n",
        "        valid_actions = valid_moves(board)\n",
        "        action = agent.select_action(board, valid_actions)\n",
        "        old_board = np.copy(board)\n",
        "        play(board, action, player)\n",
        "        reward = 0\n",
        "        if terminal_state(board) is not None:\n",
        "            if terminal_state(board) == player:\n",
        "                reward = 1\n",
        "            elif terminal_state(board) == -player:\n",
        "                reward = -1\n",
        "        agent.update(old_board, action, reward, board)\n",
        "        player = -player\n",
        "\n",
        "# Training the agent\n",
        "num_episodes = 10000\n",
        "agent = QLearningAgent()\n",
        "for i in range(num_episodes):\n",
        "    play_game(agent)\n",
        "\n",
        "# You can now use the trained agent to play the Connect 4 game\n"
      ],
      "metadata": {
        "id": "Jd2JxM6mFva4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_move(board: np.ndarray, player: int,max_depth: int = MAX_DEPTH):\n",
        "    # FIRST/SECOND MOVE -> always play central\n",
        "    if not board.any() or round_number(board) == 1:\n",
        "        play(board, 3, player)\n",
        "        return 3\n",
        "\n",
        "    # THIRD MOVE -> always play in one of the 3 cells in the center\n",
        "    if round_number(board) == 2:\n",
        "        move = np.random.choice([2, 3, 4])\n",
        "        play(board, move, player)\n",
        "        return move\n",
        "\n",
        "    # MCTS for 1 Minimax for -1\n",
        "    if(player==1):\n",
        "        move = MCTS(board, player, NUM_ITERATIONS)\n",
        "    if(player==-1):\n",
        "         _, move = minimax(board, player, depth=1, alpha=-1000, beta=1000, max_depth=max_depth)\n",
        "    play(board, move, player)\n",
        "\n",
        "    return move\n"
      ],
      "metadata": {
        "id": "A-cPqZTempR0"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def play_game():\n",
        "    board = initialize_board()\n",
        "    player = 1\n",
        "\n",
        "    while True:\n",
        "        move = choose_move(board, player, max_depth=1)\n",
        "\n",
        "        if move is None:\n",
        "            print(\"DRAW\")\n",
        "            return\n",
        "\n",
        "        print(f\"{PLAYERS[player]} TURN -> {move + 1}\")\n",
        "        display(board)\n",
        "\n",
        "        if four_in_a_row(board, player):\n",
        "            print(f\"\\nPlayer {PLAYERS[player]} WON\")\n",
        "            return\n",
        "\n",
        "        print()\n",
        "        player = -player\n",
        "\n",
        "play_game()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xcu4lkwrpSTq",
        "outputId": "74a9752c-b854-4c07-edc4-e2628032036e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A TURN -> 4\n",
            "- - - - - - - \n",
            "- - - - - - - \n",
            "- - - - - - - \n",
            "- - - - - - - \n",
            "- - - - - - - \n",
            "- - - A - - - \n",
            "\n",
            "B TURN -> 4\n",
            "- - - - - - - \n",
            "- - - - - - - \n",
            "- - - - - - - \n",
            "- - - - - - - \n",
            "- - - B - - - \n",
            "- - - A - - - \n",
            "\n",
            "A TURN -> 3\n",
            "- - - - - - - \n",
            "- - - - - - - \n",
            "- - - - - - - \n",
            "- - - - - - - \n",
            "- - - B - - - \n",
            "- - A A - - - \n",
            "\n",
            "B TURN -> 5\n",
            "- - - - - - - \n",
            "- - - - - - - \n",
            "- - - - - - - \n",
            "- - - - - - - \n",
            "- - - B - - - \n",
            "- - A A B - - \n",
            "\n",
            "A TURN -> 5\n",
            "- - - - - - - \n",
            "- - - - - - - \n",
            "- - - - - - - \n",
            "- - - - - - - \n",
            "- - - B A - - \n",
            "- - A A B - - \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-f05d825537b5>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mplayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mplay_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-f05d825537b5>\u001b[0m in \u001b[0;36mplay_game\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mmove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchoose_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmove\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-b242eaa21556>\u001b[0m in \u001b[0;36mchoose_move\u001b[0;34m(board, player, max_depth)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mmove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMCTS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_ITERATIONS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m          \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-b1d3963847fe>\u001b[0m in \u001b[0;36mminimax\u001b[0;34m(board, player, depth, alpha, beta, max_depth)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmoves\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mtake_back\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-b1d3963847fe>\u001b[0m in \u001b[0;36mminimax\u001b[0;34m(board, player, depth, alpha, beta, max_depth)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmoves\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mtake_back\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-b1d3963847fe>\u001b[0m in \u001b[0;36mminimax\u001b[0;34m(board, player, depth, alpha, beta, max_depth)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmoves\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mtake_back\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-b1d3963847fe>\u001b[0m in \u001b[0;36mminimax\u001b[0;34m(board, player, depth, alpha, beta, max_depth)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;31m# Montecarlo simulation if DEPTH too high\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmc_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;31m# MinMax exploration if DEPTH is low enough\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-b1d3963847fe>\u001b[0m in \u001b[0;36mmc_simulation\u001b[0;34m(board, player)\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mfour_in_a_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_player\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtmp_player\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mMAX_ROUNDS\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mround_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_board\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-6ae3fc62c23f>\u001b[0m in \u001b[0;36mfour_in_a_row\u001b[0;34m(board, player)\u001b[0m\n\u001b[1;32m     37\u001b[0m             )\n\u001b[1;32m     38\u001b[0m         )\n\u001b[0;32m---> 39\u001b[0;31m         or any(\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             for diag in (\n",
            "\u001b[0;32m<ipython-input-31-6ae3fc62c23f>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     38\u001b[0m         )\n\u001b[1;32m     39\u001b[0m         or any(\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             for diag in (\n\u001b[1;32m     42\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mro\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFOUR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mco\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFOUR\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mco\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}